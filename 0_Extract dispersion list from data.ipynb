{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load IGRF coefficients ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functions import data_preprocess_functions\n",
    "import glob\n",
    "import importlib\n",
    "import numpy as np\n",
    "from functions import geopack_wrapper\n",
    "\n",
    "from pyspedas import time_double\n",
    "from pyspedas import time_string\n",
    "import datetime as datetime\n",
    "\n",
    "#from functions import pygeo_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_300_name = 'idl_plots/output_sc1_sp3_300sec_multi_pa2_en2_subtraction_reduced_removebi_flux0.500.751.00_pap3.02.01.1/'\n",
    "\n",
    "dir_120_name = 'idl_plots/output_sc1_sp3_120sec_multi_pa2_en2_subtraction_reduced_removebi_flux0.500.751.00_pap3.02.01.1/data_withoutweight/sc1_sp3/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess data averaged over 5 minutes. The data is used for streaming O+ transport path study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(data_preprocess_functions)\n",
    "\n",
    "dir_name = dir_300_name\n",
    "\n",
    "data_dir = dir_name + 'data/sc1_sp3/'\n",
    "tplot_map_dir =  dir_name + 'tplot_map/sc1_sp3/'\n",
    "output_dir = data_dir\n",
    "\n",
    "save_to_agg_beam_ext_filename = data_dir + 'aggregated_fulldata_20170101_to_20201231.csv'\n",
    "save_to_dispersion_full_filename = data_dir + 'dispersion_20170101_to_20201231.csv'\n",
    "\n",
    "beam_filenames = sorted([i for i in glob.glob(data_dir+\"*beam.csv\") if i not in glob.glob(dir_name+\"storm_o_beam_2016*beam.csv\")] )\n",
    "external_filenames = sorted([i for i in glob.glob(data_dir+\"*external.csv\") if i not in glob.glob(dir_name+\"storm_o_beam_2016*external.csv\")])\n",
    "dispersion_filenames = sorted([i for i in glob.glob(data_dir+\"*dispersion.csv\") if i not in glob.glob(dir_name+\"storm_o_beam_2016*dispersion.csv\")])\n",
    "\n",
    "df_beam = data_preprocess_functions.read_beam_csv(beam_filenames)\n",
    "df_ext = data_preprocess_functions.read_external_csv(external_filenames)\n",
    "df_dispersion = data_preprocess_functions.read_dispersion_csv(dispersion_filenames)\n",
    "\n",
    "df_beam_ext = data_preprocess_functions.preprocess_data(pd.merge(df_beam, df_ext, on = 'time', how='outer' ),remove_large_y=False )\n",
    "agg_df_beam_ext = data_preprocess_functions.aggregate_energy(data_preprocess_functions.aggregate_angle(df_beam_ext))\n",
    "agg_df_beam_ext.to_csv(save_to_agg_beam_ext_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read directly from processed file\n",
    "idl_fulldata_filename = tplot_map_dir + 'tplot_map/fulldata_20170101_to_20201231.csv'\n",
    "save_to_idl_agg_fulldata_filename = tplot_map_dir + 'idl_aggregated_fulldata_20170101_to_20201231.csv'\n",
    "\n",
    "df_fulldata0 = pd.read_csv(idl_fulldata_filename)\n",
    "df_fulldata0 = df_fulldata0.rename(columns=str.lower)\n",
    "df_fulldata = data_preprocess_functions.preprocess_data(df_fulldata0)\n",
    "\n",
    "agg_df_fulldata = data_preprocess_functions.aggregate_energy(data_preprocess_functions.aggregate_angle(df_fulldata))\n",
    "agg_df_fulldata.to_csv(save_to_idl_agg_fulldata_filename)\n",
    "\n",
    "# dispersion list\n",
    "df_dispersion_full = pd.merge(df_dispersion, agg_df_fulldata, on = 'time', how = 'left')\n",
    "df_dispersion_full = data_preprocess_functions.preprocess_dispersion_list(df_dispersion_full, model = 't89')\n",
    "df_dispersion_full.to_csv(save_to_dispersion_full_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'n_para_weighted'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'n_para_weighted'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m df_fulldata0 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(idl_fulldata_filename)\n\u001b[1;32m      6\u001b[0m df_fulldata0 \u001b[38;5;241m=\u001b[39m df_fulldata0\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mlower)\n\u001b[0;32m----> 7\u001b[0m df_fulldata \u001b[38;5;241m=\u001b[39m data_preprocess_functions\u001b[38;5;241m.\u001b[39mpreprocess_data(df_fulldata0)\n\u001b[1;32m      9\u001b[0m agg_df_fulldata \u001b[38;5;241m=\u001b[39m data_preprocess_functions\u001b[38;5;241m.\u001b[39maggregate_energy(data_preprocess_functions\u001b[38;5;241m.\u001b[39maggregate_angle(df_fulldata))\n\u001b[1;32m     10\u001b[0m agg_df_fulldata\u001b[38;5;241m.\u001b[39mto_csv(save_to_idl_agg_fulldata_filename)\n",
      "File \u001b[0;32m~/workspace/GitHub/mms_o_dispersion_analysis/functions/data_preprocess_functions.py:266\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(data, remove_large_y, avg_hour)\u001b[0m\n\u001b[1;32m    263\u001b[0m cooked_data \u001b[38;5;241m=\u001b[39m extract_hemisphere(cooked_data)\n\u001b[1;32m    265\u001b[0m cooked_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflag\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 266\u001b[0m cooked_data \u001b[38;5;241m=\u001b[39m extract_beam_info(cooked_data,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpara\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    267\u001b[0m cooked_data \u001b[38;5;241m=\u001b[39m extract_beam_info(cooked_data,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manti\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    269\u001b[0m cooked_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy_int\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(cooked_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m'\u001b[39m])    \n",
      "File \u001b[0;32m~/workspace/GitHub/mms_o_dispersion_analysis/functions/data_preprocess_functions.py:197\u001b[0m, in \u001b[0;36mextract_beam_info\u001b[0;34m(mydf, direction)\u001b[0m\n\u001b[1;32m    194\u001b[0m mydf\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mydf\u001b[38;5;241m.\u001b[39mloc[index,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mdirection]\n\u001b[1;32m    195\u001b[0m mydf\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mydf\u001b[38;5;241m.\u001b[39mloc[index,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mdirection]\n\u001b[0;32m--> 197\u001b[0m mydf\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mydf\u001b[38;5;241m.\u001b[39mloc[index,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mdirection\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    199\u001b[0m mydf\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimfBy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mydf\u001b[38;5;241m.\u001b[39mloc[index,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimf_by_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mdirection\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_1h\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    200\u001b[0m mydf\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimfBz\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mydf\u001b[38;5;241m.\u001b[39mloc[index,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimf_bz_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mdirection\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_1h\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1096\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1097\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1280\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1279\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(tup)\n\u001b[0;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1000\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tup):\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_label_like(key):\n\u001b[1;32m    998\u001b[0m         \u001b[38;5;66;03m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;66;03m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[0;32m-> 1000\u001b[0m         section \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(key, axis\u001b[38;5;241m=\u001b[39mi)\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         \u001b[38;5;66;03m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m         \u001b[38;5;66;03m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m section\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m   1006\u001b[0m             \u001b[38;5;66;03m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m             \u001b[38;5;66;03m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_label(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1293\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mxs(label, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4082\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_level:\n\u001b[0;32m-> 4082\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m   4083\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'n_para_weighted'"
     ]
    }
   ],
   "source": [
    "# read directly from processed file\n",
    "idl_fulldata_filename = dir_name + 'tplot_map/tplot_map/fulldata_20170101_to_20201231.csv'\n",
    "save_to_idl_agg_fulldata_filename = dir_name + 'idl_aggregated_fulldata_20170101_to_20201231.csv'\n",
    "\n",
    "df_fulldata0 = pd.read_csv(idl_fulldata_filename)\n",
    "df_fulldata0 = df_fulldata0.rename(columns=str.lower)\n",
    "df_fulldata = data_preprocess_functions.preprocess_data(df_fulldata0)\n",
    "\n",
    "agg_df_fulldata = data_preprocess_functions.aggregate_energy(data_preprocess_functions.aggregate_angle(df_fulldata))\n",
    "agg_df_fulldata.to_csv(save_to_idl_agg_fulldata_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read, combine and preprosess the data for dispersion study (nightside auroral outflowing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data_preprocess_functions)\n",
    "\n",
    "dir_name = dir_120_name\n",
    "\n",
    "# save_to_agg_beam_ext_filename = dir_name + 'aggregated_fulldata_20160101_to_20201231.csv'\n",
    "save_to_dispersion_full_filename = dir_name + 'dispersion_20160101_to_20201231.csv'\n",
    "\n",
    "dispersion_filenames = sorted(glob.glob(dir_name+\"data/*dispersion.csv\"))\n",
    "beam_filenames = [s.replace('dispersion','beam') for s in dispersion_filenames]\n",
    "external_filenames = [s.replace('dispersion','external') for s in dispersion_filenames] \n",
    "\n",
    "df_beam = data_preprocess_functions.read_beam_csv(beam_filenames)\n",
    "df_ext = data_preprocess_functions.read_external_csv(external_filenames)\n",
    "df_dispersion = data_preprocess_functions.read_dispersion_csv(dispersion_filenames)\n",
    "\n",
    "df_beam_ext = data_preprocess_functions.preprocess_data(pd.merge(df_beam, df_ext, on = 'time', how='outer' ),remove_large_y=False )\n",
    "agg_df_beam_ext = data_preprocess_functions.aggregate_energy(data_preprocess_functions.aggregate_angle(df_beam_ext))\n",
    "# agg_df_beam_ext.to_csv(save_to_agg_beam_ext_filename)\n",
    "\n",
    "# read directly from processed file\n",
    "idl_fulldata_filename = dir_name + 'tplot_map/tplot_map/fulldata_20160101_to_20201231.csv'\n",
    "save_to_idl_agg_fulldata_filename = dir_name + 'idl_aggregated_fulldata_20160101_to_20201231.csv'\n",
    "\n",
    "df_fulldata0 = pd.read_csv(idl_fulldata_filename)\n",
    "df_fulldata0 = df_fulldata0.rename(columns=str.lower)\n",
    "df_fulldata = data_preprocess_functions.preprocess_data(df_fulldata0)\n",
    "\n",
    "agg_df_fulldata = data_preprocess_functions.aggregate_energy(data_preprocess_functions.aggregate_angle(df_fulldata))\n",
    "agg_df_fulldata.to_csv(save_to_idl_agg_fulldata_filename)\n",
    "\n",
    "df_dispersion_full = pd.merge(df_dispersion, agg_df_fulldata, on = 'time', how = 'left')\n",
    "df_dispersion_full = df_dispersion_full[df_dispersion_full['kp'] >= 0]\n",
    "df_dispersion_full = data_preprocess_functions.preprocess_dispersion_list(df_dispersion_full, model = 't89')\n",
    "df_dispersion_full.to_csv(save_to_dispersion_full_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
